{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8bQ4YTI_-3p"
   },
   "source": [
    "**Sungkyung Shon, Artificial Intelligence, Aston university, Birmingham, United Kingdom**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OoxZp76kIaMZ",
    "outputId": "2607735a-20d4-4e34-8c7b-b72138b99ca7"
   },
   "outputs": [],
   "source": [
    "!pip install boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8lpqpDzmFruX"
   },
   "outputs": [],
   "source": [
    "import csv as csv \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import datetime\n",
    "import os\n",
    "import warnings\n",
    "import re\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt                        # For plotting data\n",
    "import seaborn as sns                                     # For plotting data\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier      #DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier   #RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from boruta import BorutaPy\n",
    "from imblearn.under_sampling import RandomUnderSampler   #RandomUnderSampler\n",
    "from sklearn.linear_model import LogisticRegression      #LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline     #pipeline\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import GroupKFold  # For optimization\n",
    "from pandas import DataFrame                       # For dataframes\n",
    "from numpy import ravel                                  # For matrices\n",
    "from sklearn.model_selection import train_test_split    # For train/test splits\n",
    "from sklearn.neighbors import KNeighborsClassifier    # The k-nearest neighbor classifier\n",
    "from sklearn.feature_selection import VarianceThreshold # Feature selector\n",
    "from sklearn.pipeline import Pipeline                                  # For setting up pipeline\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler, PowerTransformer, MaxAbsScaler, LabelEncoder# Various pre-processing steps\n",
    "from sklearn.feature_selection import mutual_info_classif \n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('df_training_level3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Info_PepID</th>\n",
       "      <th>Info_organism_id</th>\n",
       "      <th>Info_protein_id</th>\n",
       "      <th>Info_pos</th>\n",
       "      <th>Info_AA</th>\n",
       "      <th>Info_pubmed_id</th>\n",
       "      <th>Info_epitope_id</th>\n",
       "      <th>Info_host_id</th>\n",
       "      <th>Info_nPos</th>\n",
       "      <th>Info_nNeg</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_esm1b_1270</th>\n",
       "      <th>feat_esm1b_1271</th>\n",
       "      <th>feat_esm1b_1272</th>\n",
       "      <th>feat_esm1b_1273</th>\n",
       "      <th>feat_esm1b_1274</th>\n",
       "      <th>feat_esm1b_1275</th>\n",
       "      <th>feat_esm1b_1276</th>\n",
       "      <th>feat_esm1b_1277</th>\n",
       "      <th>feat_esm1b_1278</th>\n",
       "      <th>feat_esm1b_1279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NP_775663.1:2</td>\n",
       "      <td>11072</td>\n",
       "      <td>NP_775663.1</td>\n",
       "      <td>2</td>\n",
       "      <td>T</td>\n",
       "      <td>8725101</td>\n",
       "      <td>64601</td>\n",
       "      <td>9606</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235874</td>\n",
       "      <td>-0.186116</td>\n",
       "      <td>-0.007055</td>\n",
       "      <td>0.227716</td>\n",
       "      <td>-1.469320</td>\n",
       "      <td>0.024950</td>\n",
       "      <td>0.054577</td>\n",
       "      <td>0.142123</td>\n",
       "      <td>0.194421</td>\n",
       "      <td>0.471760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NP_775663.1:2</td>\n",
       "      <td>11072</td>\n",
       "      <td>NP_775663.1</td>\n",
       "      <td>3</td>\n",
       "      <td>K</td>\n",
       "      <td>8725101</td>\n",
       "      <td>64601</td>\n",
       "      <td>9606</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014759</td>\n",
       "      <td>-0.119949</td>\n",
       "      <td>-0.016030</td>\n",
       "      <td>0.040704</td>\n",
       "      <td>-1.614884</td>\n",
       "      <td>0.189634</td>\n",
       "      <td>-0.049600</td>\n",
       "      <td>0.005898</td>\n",
       "      <td>0.128652</td>\n",
       "      <td>0.254778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NP_775663.1:2</td>\n",
       "      <td>11072</td>\n",
       "      <td>NP_775663.1</td>\n",
       "      <td>4</td>\n",
       "      <td>K</td>\n",
       "      <td>8725101</td>\n",
       "      <td>64601</td>\n",
       "      <td>9606</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066743</td>\n",
       "      <td>-0.165863</td>\n",
       "      <td>-0.061832</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>-1.353973</td>\n",
       "      <td>0.140752</td>\n",
       "      <td>-0.168214</td>\n",
       "      <td>0.114217</td>\n",
       "      <td>-0.002818</td>\n",
       "      <td>0.247916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NP_775663.1:2</td>\n",
       "      <td>11072</td>\n",
       "      <td>NP_775663.1</td>\n",
       "      <td>5</td>\n",
       "      <td>P</td>\n",
       "      <td>8725101</td>\n",
       "      <td>64601</td>\n",
       "      <td>9606</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.148641</td>\n",
       "      <td>-0.088860</td>\n",
       "      <td>-0.218482</td>\n",
       "      <td>0.103855</td>\n",
       "      <td>-1.252338</td>\n",
       "      <td>-0.000789</td>\n",
       "      <td>0.049453</td>\n",
       "      <td>0.197773</td>\n",
       "      <td>0.034994</td>\n",
       "      <td>0.303203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NP_775663.1:2</td>\n",
       "      <td>11072</td>\n",
       "      <td>NP_775663.1</td>\n",
       "      <td>6</td>\n",
       "      <td>G</td>\n",
       "      <td>8725101</td>\n",
       "      <td>64601</td>\n",
       "      <td>9606</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251960</td>\n",
       "      <td>-0.122903</td>\n",
       "      <td>-0.191698</td>\n",
       "      <td>0.142125</td>\n",
       "      <td>-0.985092</td>\n",
       "      <td>0.029431</td>\n",
       "      <td>0.176924</td>\n",
       "      <td>0.302354</td>\n",
       "      <td>-0.138180</td>\n",
       "      <td>0.136602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1294 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Info_PepID  Info_organism_id Info_protein_id  Info_pos Info_AA  \\\n",
       "0  NP_775663.1:2             11072     NP_775663.1         2       T   \n",
       "1  NP_775663.1:2             11072     NP_775663.1         3       K   \n",
       "2  NP_775663.1:2             11072     NP_775663.1         4       K   \n",
       "3  NP_775663.1:2             11072     NP_775663.1         5       P   \n",
       "4  NP_775663.1:2             11072     NP_775663.1         6       G   \n",
       "\n",
       "  Info_pubmed_id Info_epitope_id Info_host_id Info_nPos Info_nNeg  ...  \\\n",
       "0        8725101           64601         9606         2         1  ...   \n",
       "1        8725101           64601         9606         2         1  ...   \n",
       "2        8725101           64601         9606         2         1  ...   \n",
       "3        8725101           64601         9606         2         1  ...   \n",
       "4        8725101           64601         9606         2         1  ...   \n",
       "\n",
       "  feat_esm1b_1270 feat_esm1b_1271  feat_esm1b_1272  feat_esm1b_1273  \\\n",
       "0        0.235874       -0.186116        -0.007055         0.227716   \n",
       "1        0.014759       -0.119949        -0.016030         0.040704   \n",
       "2        0.066743       -0.165863        -0.061832         0.026400   \n",
       "3       -0.148641       -0.088860        -0.218482         0.103855   \n",
       "4        0.251960       -0.122903        -0.191698         0.142125   \n",
       "\n",
       "   feat_esm1b_1274  feat_esm1b_1275  feat_esm1b_1276  feat_esm1b_1277  \\\n",
       "0        -1.469320         0.024950         0.054577         0.142123   \n",
       "1        -1.614884         0.189634        -0.049600         0.005898   \n",
       "2        -1.353973         0.140752        -0.168214         0.114217   \n",
       "3        -1.252338        -0.000789         0.049453         0.197773   \n",
       "4        -0.985092         0.029431         0.176924         0.302354   \n",
       "\n",
       "   feat_esm1b_1278  feat_esm1b_1279  \n",
       "0         0.194421         0.471760  \n",
       "1         0.128652         0.254778  \n",
       "2        -0.002818         0.247916  \n",
       "3         0.034994         0.303203  \n",
       "4        -0.138180         0.136602  \n",
       "\n",
       "[5 rows x 1294 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "9dzQSkk8Fxw0",
    "outputId": "35458e1c-043c-4fdb-b03e-450d3e489348",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_esm1b_0</th>\n",
       "      <th>feat_esm1b_1</th>\n",
       "      <th>feat_esm1b_2</th>\n",
       "      <th>feat_esm1b_3</th>\n",
       "      <th>feat_esm1b_4</th>\n",
       "      <th>feat_esm1b_5</th>\n",
       "      <th>feat_esm1b_6</th>\n",
       "      <th>feat_esm1b_7</th>\n",
       "      <th>feat_esm1b_8</th>\n",
       "      <th>feat_esm1b_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_esm1b_1270</th>\n",
       "      <th>feat_esm1b_1271</th>\n",
       "      <th>feat_esm1b_1272</th>\n",
       "      <th>feat_esm1b_1273</th>\n",
       "      <th>feat_esm1b_1274</th>\n",
       "      <th>feat_esm1b_1275</th>\n",
       "      <th>feat_esm1b_1276</th>\n",
       "      <th>feat_esm1b_1277</th>\n",
       "      <th>feat_esm1b_1278</th>\n",
       "      <th>feat_esm1b_1279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.115278</td>\n",
       "      <td>0.105343</td>\n",
       "      <td>0.256809</td>\n",
       "      <td>0.205551</td>\n",
       "      <td>-0.162306</td>\n",
       "      <td>-0.250113</td>\n",
       "      <td>-0.039983</td>\n",
       "      <td>-0.221369</td>\n",
       "      <td>0.016626</td>\n",
       "      <td>0.105289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235874</td>\n",
       "      <td>-0.186116</td>\n",
       "      <td>-0.007055</td>\n",
       "      <td>0.227716</td>\n",
       "      <td>-1.469320</td>\n",
       "      <td>0.024950</td>\n",
       "      <td>0.054577</td>\n",
       "      <td>0.142123</td>\n",
       "      <td>0.194421</td>\n",
       "      <td>0.471760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.048915</td>\n",
       "      <td>-0.060122</td>\n",
       "      <td>0.054565</td>\n",
       "      <td>0.130224</td>\n",
       "      <td>-0.243280</td>\n",
       "      <td>0.032289</td>\n",
       "      <td>-0.035078</td>\n",
       "      <td>0.149056</td>\n",
       "      <td>-0.050518</td>\n",
       "      <td>-0.056080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014759</td>\n",
       "      <td>-0.119949</td>\n",
       "      <td>-0.016030</td>\n",
       "      <td>0.040704</td>\n",
       "      <td>-1.614884</td>\n",
       "      <td>0.189634</td>\n",
       "      <td>-0.049600</td>\n",
       "      <td>0.005898</td>\n",
       "      <td>0.128652</td>\n",
       "      <td>0.254778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029908</td>\n",
       "      <td>-0.069993</td>\n",
       "      <td>0.144604</td>\n",
       "      <td>0.031607</td>\n",
       "      <td>-0.157991</td>\n",
       "      <td>0.096214</td>\n",
       "      <td>-0.073147</td>\n",
       "      <td>0.150113</td>\n",
       "      <td>-0.123229</td>\n",
       "      <td>-0.060424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066743</td>\n",
       "      <td>-0.165863</td>\n",
       "      <td>-0.061832</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>-1.353973</td>\n",
       "      <td>0.140752</td>\n",
       "      <td>-0.168214</td>\n",
       "      <td>0.114217</td>\n",
       "      <td>-0.002818</td>\n",
       "      <td>0.247916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.017817</td>\n",
       "      <td>0.063682</td>\n",
       "      <td>0.196507</td>\n",
       "      <td>0.219516</td>\n",
       "      <td>0.010169</td>\n",
       "      <td>0.048974</td>\n",
       "      <td>-0.102324</td>\n",
       "      <td>-0.071483</td>\n",
       "      <td>-0.063823</td>\n",
       "      <td>-0.034733</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.148641</td>\n",
       "      <td>-0.088860</td>\n",
       "      <td>-0.218482</td>\n",
       "      <td>0.103855</td>\n",
       "      <td>-1.252338</td>\n",
       "      <td>-0.000789</td>\n",
       "      <td>0.049453</td>\n",
       "      <td>0.197773</td>\n",
       "      <td>0.034994</td>\n",
       "      <td>0.303203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.183947</td>\n",
       "      <td>-0.002784</td>\n",
       "      <td>0.185983</td>\n",
       "      <td>0.299326</td>\n",
       "      <td>-0.256938</td>\n",
       "      <td>0.004182</td>\n",
       "      <td>-0.194807</td>\n",
       "      <td>-0.299934</td>\n",
       "      <td>-0.283545</td>\n",
       "      <td>-0.025699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251960</td>\n",
       "      <td>-0.122903</td>\n",
       "      <td>-0.191698</td>\n",
       "      <td>0.142125</td>\n",
       "      <td>-0.985092</td>\n",
       "      <td>0.029431</td>\n",
       "      <td>0.176924</td>\n",
       "      <td>0.302354</td>\n",
       "      <td>-0.138180</td>\n",
       "      <td>0.136602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feat_esm1b_0  feat_esm1b_1  feat_esm1b_2  feat_esm1b_3  feat_esm1b_4  \\\n",
       "0      0.115278      0.105343      0.256809      0.205551     -0.162306   \n",
       "1      0.048915     -0.060122      0.054565      0.130224     -0.243280   \n",
       "2      0.029908     -0.069993      0.144604      0.031607     -0.157991   \n",
       "3     -0.017817      0.063682      0.196507      0.219516      0.010169   \n",
       "4      0.183947     -0.002784      0.185983      0.299326     -0.256938   \n",
       "\n",
       "   feat_esm1b_5  feat_esm1b_6  feat_esm1b_7  feat_esm1b_8  feat_esm1b_9  ...  \\\n",
       "0     -0.250113     -0.039983     -0.221369      0.016626      0.105289  ...   \n",
       "1      0.032289     -0.035078      0.149056     -0.050518     -0.056080  ...   \n",
       "2      0.096214     -0.073147      0.150113     -0.123229     -0.060424  ...   \n",
       "3      0.048974     -0.102324     -0.071483     -0.063823     -0.034733  ...   \n",
       "4      0.004182     -0.194807     -0.299934     -0.283545     -0.025699  ...   \n",
       "\n",
       "   feat_esm1b_1270  feat_esm1b_1271  feat_esm1b_1272  feat_esm1b_1273  \\\n",
       "0         0.235874        -0.186116        -0.007055         0.227716   \n",
       "1         0.014759        -0.119949        -0.016030         0.040704   \n",
       "2         0.066743        -0.165863        -0.061832         0.026400   \n",
       "3        -0.148641        -0.088860        -0.218482         0.103855   \n",
       "4         0.251960        -0.122903        -0.191698         0.142125   \n",
       "\n",
       "   feat_esm1b_1274  feat_esm1b_1275  feat_esm1b_1276  feat_esm1b_1277  \\\n",
       "0        -1.469320         0.024950         0.054577         0.142123   \n",
       "1        -1.614884         0.189634        -0.049600         0.005898   \n",
       "2        -1.353973         0.140752        -0.168214         0.114217   \n",
       "3        -1.252338        -0.000789         0.049453         0.197773   \n",
       "4        -0.985092         0.029431         0.176924         0.302354   \n",
       "\n",
       "   feat_esm1b_1278  feat_esm1b_1279  \n",
       "0         0.194421         0.471760  \n",
       "1         0.128652         0.254778  \n",
       "2        -0.002818         0.247916  \n",
       "3         0.034994         0.303203  \n",
       "4        -0.138180         0.136602  \n",
       "\n",
       "[5 rows x 1280 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove the information columns and the 'Class' column\n",
    "df_features = df.filter(regex='feat_esm1b_')\n",
    "feature_columns = [col for col in df.columns if col.startswith('feat_esm1b_')]\n",
    "filtered_df = df[feature_columns]\n",
    "class_column = df['Class']\n",
    "display(filtered_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yjcjzi2FFx4n",
    "outputId": "599dc324-447a-4929-c7b5-08ebf92e4814",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72663 entries, 0 to 72662\n",
      "Columns: 1294 entries, Info_PepID to feat_esm1b_1279\n",
      "dtypes: float64(1280), int64(4), object(10)\n",
      "memory usage: 717.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "feat_esm1b_633    1912\n",
       "feat_esm1b_876    1912\n",
       "feat_esm1b_854    1912\n",
       "feat_esm1b_853    1912\n",
       "feat_esm1b_852    1912\n",
       "                  ... \n",
       "Info_type            0\n",
       "Info_window          0\n",
       "Info_cluster         0\n",
       "Class                0\n",
       "Info_PepID           0\n",
       "Length: 1294, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#specify the number of entries, the number of non-null elements, and the kind of variable.\n",
    "df.info()\n",
    "#detect missing values\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqdU2MhU_-3u"
   },
   "source": [
    "**DataFrame information such as the number of items, the number of non-null components, and the type of variable in each column are provided. It also computes the percentage of each column and the number of missing values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "no58wYe6Fx9o",
    "outputId": "577c23b3-31bf-439b-e6b3-6bdd1436689f",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Info_PepID          0.000000\n",
       "Info_organism_id    0.000000\n",
       "Info_protein_id     0.000000\n",
       "Info_pos            0.000000\n",
       "Info_AA             0.000000\n",
       "                      ...   \n",
       "feat_esm1b_1275     2.631325\n",
       "feat_esm1b_1276     2.631325\n",
       "feat_esm1b_1277     2.631325\n",
       "feat_esm1b_1278     2.631325\n",
       "feat_esm1b_1279     2.631325\n",
       "Length: 1294, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the percentage of missing values, such that we can determine how to deal with variables having a high count\n",
    "df.isnull().sum()/len(df)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z-gnakFWFx_r",
    "outputId": "c4b0da3a-628c-490b-c3b7-a989a298de57"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9dFqvg5gFyCG",
    "outputId": "c6d6ec06-6dd1-42d3-f167-83c900e828dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Info_PepID', 'Info_organism_id', 'Info_protein_id', 'Info_pos', 'Info_AA', 'Info_pubmed_id', 'Info_epitope_id', 'Info_host_id', 'Info_nPos', 'Info_nNeg', 'Info_type', 'Info_window', 'Info_cluster']\n"
     ]
    }
   ],
   "source": [
    "pattern = re.compile(r'^Info.*')\n",
    "matching_columns = [col for col in df.columns if pattern.match(col)]\n",
    "print(matching_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "Kps-2ROxIvu5",
    "outputId": "29f60526-b42c-429e-8c8e-783a9504070d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Info_cluster</th>\n",
       "      <th>Class</th>\n",
       "      <th>feat_esm1b_0</th>\n",
       "      <th>feat_esm1b_1</th>\n",
       "      <th>feat_esm1b_2</th>\n",
       "      <th>feat_esm1b_3</th>\n",
       "      <th>feat_esm1b_4</th>\n",
       "      <th>feat_esm1b_5</th>\n",
       "      <th>feat_esm1b_6</th>\n",
       "      <th>feat_esm1b_7</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_esm1b_1270</th>\n",
       "      <th>feat_esm1b_1271</th>\n",
       "      <th>feat_esm1b_1272</th>\n",
       "      <th>feat_esm1b_1273</th>\n",
       "      <th>feat_esm1b_1274</th>\n",
       "      <th>feat_esm1b_1275</th>\n",
       "      <th>feat_esm1b_1276</th>\n",
       "      <th>feat_esm1b_1277</th>\n",
       "      <th>feat_esm1b_1278</th>\n",
       "      <th>feat_esm1b_1279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.115278</td>\n",
       "      <td>0.105343</td>\n",
       "      <td>0.256809</td>\n",
       "      <td>0.205551</td>\n",
       "      <td>-0.162306</td>\n",
       "      <td>-0.250113</td>\n",
       "      <td>-0.039983</td>\n",
       "      <td>-0.221369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235874</td>\n",
       "      <td>-0.186116</td>\n",
       "      <td>-0.007055</td>\n",
       "      <td>0.227716</td>\n",
       "      <td>-1.469320</td>\n",
       "      <td>0.024950</td>\n",
       "      <td>0.054577</td>\n",
       "      <td>0.142123</td>\n",
       "      <td>0.194421</td>\n",
       "      <td>0.471760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048915</td>\n",
       "      <td>-0.060122</td>\n",
       "      <td>0.054565</td>\n",
       "      <td>0.130224</td>\n",
       "      <td>-0.243280</td>\n",
       "      <td>0.032289</td>\n",
       "      <td>-0.035078</td>\n",
       "      <td>0.149056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014759</td>\n",
       "      <td>-0.119949</td>\n",
       "      <td>-0.016030</td>\n",
       "      <td>0.040704</td>\n",
       "      <td>-1.614884</td>\n",
       "      <td>0.189634</td>\n",
       "      <td>-0.049600</td>\n",
       "      <td>0.005898</td>\n",
       "      <td>0.128652</td>\n",
       "      <td>0.254778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029908</td>\n",
       "      <td>-0.069993</td>\n",
       "      <td>0.144604</td>\n",
       "      <td>0.031607</td>\n",
       "      <td>-0.157991</td>\n",
       "      <td>0.096214</td>\n",
       "      <td>-0.073147</td>\n",
       "      <td>0.150113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066743</td>\n",
       "      <td>-0.165863</td>\n",
       "      <td>-0.061832</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>-1.353973</td>\n",
       "      <td>0.140752</td>\n",
       "      <td>-0.168214</td>\n",
       "      <td>0.114217</td>\n",
       "      <td>-0.002818</td>\n",
       "      <td>0.247916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.017817</td>\n",
       "      <td>0.063682</td>\n",
       "      <td>0.196507</td>\n",
       "      <td>0.219516</td>\n",
       "      <td>0.010169</td>\n",
       "      <td>0.048974</td>\n",
       "      <td>-0.102324</td>\n",
       "      <td>-0.071483</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.148641</td>\n",
       "      <td>-0.088860</td>\n",
       "      <td>-0.218482</td>\n",
       "      <td>0.103855</td>\n",
       "      <td>-1.252338</td>\n",
       "      <td>-0.000789</td>\n",
       "      <td>0.049453</td>\n",
       "      <td>0.197773</td>\n",
       "      <td>0.034994</td>\n",
       "      <td>0.303203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.183947</td>\n",
       "      <td>-0.002784</td>\n",
       "      <td>0.185983</td>\n",
       "      <td>0.299326</td>\n",
       "      <td>-0.256938</td>\n",
       "      <td>0.004182</td>\n",
       "      <td>-0.194807</td>\n",
       "      <td>-0.299934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251960</td>\n",
       "      <td>-0.122903</td>\n",
       "      <td>-0.191698</td>\n",
       "      <td>0.142125</td>\n",
       "      <td>-0.985092</td>\n",
       "      <td>0.029431</td>\n",
       "      <td>0.176924</td>\n",
       "      <td>0.302354</td>\n",
       "      <td>-0.138180</td>\n",
       "      <td>0.136602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72658</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.060893</td>\n",
       "      <td>0.387238</td>\n",
       "      <td>0.030345</td>\n",
       "      <td>0.005711</td>\n",
       "      <td>-0.147543</td>\n",
       "      <td>0.013120</td>\n",
       "      <td>-0.260891</td>\n",
       "      <td>0.104144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289453</td>\n",
       "      <td>-0.096301</td>\n",
       "      <td>0.030024</td>\n",
       "      <td>0.195304</td>\n",
       "      <td>-0.801965</td>\n",
       "      <td>-0.274976</td>\n",
       "      <td>0.178286</td>\n",
       "      <td>0.165846</td>\n",
       "      <td>0.177845</td>\n",
       "      <td>0.332194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72659</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.199185</td>\n",
       "      <td>0.368873</td>\n",
       "      <td>0.180725</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>-0.017099</td>\n",
       "      <td>-0.028999</td>\n",
       "      <td>-0.153706</td>\n",
       "      <td>-0.175476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250574</td>\n",
       "      <td>-0.246241</td>\n",
       "      <td>0.077579</td>\n",
       "      <td>-0.052833</td>\n",
       "      <td>-0.979619</td>\n",
       "      <td>-0.031028</td>\n",
       "      <td>0.186897</td>\n",
       "      <td>0.133366</td>\n",
       "      <td>0.157032</td>\n",
       "      <td>0.341441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72660</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.180276</td>\n",
       "      <td>0.448252</td>\n",
       "      <td>-0.102101</td>\n",
       "      <td>0.106668</td>\n",
       "      <td>-0.206699</td>\n",
       "      <td>-0.118161</td>\n",
       "      <td>0.044999</td>\n",
       "      <td>-0.046077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170998</td>\n",
       "      <td>-0.051927</td>\n",
       "      <td>-0.083331</td>\n",
       "      <td>0.035247</td>\n",
       "      <td>-1.028582</td>\n",
       "      <td>-0.234735</td>\n",
       "      <td>-0.006005</td>\n",
       "      <td>0.206064</td>\n",
       "      <td>0.058616</td>\n",
       "      <td>0.237192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72661</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.274478</td>\n",
       "      <td>0.362613</td>\n",
       "      <td>0.431246</td>\n",
       "      <td>0.164276</td>\n",
       "      <td>-0.130307</td>\n",
       "      <td>-0.204145</td>\n",
       "      <td>0.203404</td>\n",
       "      <td>-0.083181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148796</td>\n",
       "      <td>-0.283643</td>\n",
       "      <td>0.028591</td>\n",
       "      <td>0.037022</td>\n",
       "      <td>-1.073474</td>\n",
       "      <td>-0.182251</td>\n",
       "      <td>0.221717</td>\n",
       "      <td>0.074508</td>\n",
       "      <td>0.227138</td>\n",
       "      <td>0.319858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72662</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.105644</td>\n",
       "      <td>0.424534</td>\n",
       "      <td>-0.034945</td>\n",
       "      <td>0.123983</td>\n",
       "      <td>0.052842</td>\n",
       "      <td>-0.166775</td>\n",
       "      <td>-0.204510</td>\n",
       "      <td>0.328612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215887</td>\n",
       "      <td>-0.036167</td>\n",
       "      <td>0.073127</td>\n",
       "      <td>0.121327</td>\n",
       "      <td>-0.895135</td>\n",
       "      <td>-0.023802</td>\n",
       "      <td>0.075021</td>\n",
       "      <td>0.116866</td>\n",
       "      <td>-0.004627</td>\n",
       "      <td>0.366094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72663 rows × 1282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Info_cluster  Class  feat_esm1b_0  feat_esm1b_1  feat_esm1b_2  \\\n",
       "0                 8      1      0.115278      0.105343      0.256809   \n",
       "1                 8      1      0.048915     -0.060122      0.054565   \n",
       "2                 8      1      0.029908     -0.069993      0.144604   \n",
       "3                 8      1     -0.017817      0.063682      0.196507   \n",
       "4                 8      1      0.183947     -0.002784      0.185983   \n",
       "...             ...    ...           ...           ...           ...   \n",
       "72658             8      1     -0.060893      0.387238      0.030345   \n",
       "72659             8      1      0.199185      0.368873      0.180725   \n",
       "72660             8      1     -0.180276      0.448252     -0.102101   \n",
       "72661             8      1     -0.274478      0.362613      0.431246   \n",
       "72662             8      1     -0.105644      0.424534     -0.034945   \n",
       "\n",
       "       feat_esm1b_3  feat_esm1b_4  feat_esm1b_5  feat_esm1b_6  feat_esm1b_7  \\\n",
       "0          0.205551     -0.162306     -0.250113     -0.039983     -0.221369   \n",
       "1          0.130224     -0.243280      0.032289     -0.035078      0.149056   \n",
       "2          0.031607     -0.157991      0.096214     -0.073147      0.150113   \n",
       "3          0.219516      0.010169      0.048974     -0.102324     -0.071483   \n",
       "4          0.299326     -0.256938      0.004182     -0.194807     -0.299934   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "72658      0.005711     -0.147543      0.013120     -0.260891      0.104144   \n",
       "72659      0.057800     -0.017099     -0.028999     -0.153706     -0.175476   \n",
       "72660      0.106668     -0.206699     -0.118161      0.044999     -0.046077   \n",
       "72661      0.164276     -0.130307     -0.204145      0.203404     -0.083181   \n",
       "72662      0.123983      0.052842     -0.166775     -0.204510      0.328612   \n",
       "\n",
       "       ...  feat_esm1b_1270  feat_esm1b_1271  feat_esm1b_1272  \\\n",
       "0      ...         0.235874        -0.186116        -0.007055   \n",
       "1      ...         0.014759        -0.119949        -0.016030   \n",
       "2      ...         0.066743        -0.165863        -0.061832   \n",
       "3      ...        -0.148641        -0.088860        -0.218482   \n",
       "4      ...         0.251960        -0.122903        -0.191698   \n",
       "...    ...              ...              ...              ...   \n",
       "72658  ...         0.289453        -0.096301         0.030024   \n",
       "72659  ...         0.250574        -0.246241         0.077579   \n",
       "72660  ...         0.170998        -0.051927        -0.083331   \n",
       "72661  ...         0.148796        -0.283643         0.028591   \n",
       "72662  ...         0.215887        -0.036167         0.073127   \n",
       "\n",
       "       feat_esm1b_1273  feat_esm1b_1274  feat_esm1b_1275  feat_esm1b_1276  \\\n",
       "0             0.227716        -1.469320         0.024950         0.054577   \n",
       "1             0.040704        -1.614884         0.189634        -0.049600   \n",
       "2             0.026400        -1.353973         0.140752        -0.168214   \n",
       "3             0.103855        -1.252338        -0.000789         0.049453   \n",
       "4             0.142125        -0.985092         0.029431         0.176924   \n",
       "...                ...              ...              ...              ...   \n",
       "72658         0.195304        -0.801965        -0.274976         0.178286   \n",
       "72659        -0.052833        -0.979619        -0.031028         0.186897   \n",
       "72660         0.035247        -1.028582        -0.234735        -0.006005   \n",
       "72661         0.037022        -1.073474        -0.182251         0.221717   \n",
       "72662         0.121327        -0.895135        -0.023802         0.075021   \n",
       "\n",
       "       feat_esm1b_1277  feat_esm1b_1278  feat_esm1b_1279  \n",
       "0             0.142123         0.194421         0.471760  \n",
       "1             0.005898         0.128652         0.254778  \n",
       "2             0.114217        -0.002818         0.247916  \n",
       "3             0.197773         0.034994         0.303203  \n",
       "4             0.302354        -0.138180         0.136602  \n",
       "...                ...              ...              ...  \n",
       "72658         0.165846         0.177845         0.332194  \n",
       "72659         0.133366         0.157032         0.341441  \n",
       "72660         0.206064         0.058616         0.237192  \n",
       "72661         0.074508         0.227138         0.319858  \n",
       "72662         0.116866        -0.004627         0.366094  \n",
       "\n",
       "[72663 rows x 1282 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = ['Info_PepID', 'Info_organism_id', 'Info_protein_id', 'Info_pos', 'Info_AA', 'Info_pubmed_id', 'Info_epitope_id', 'Info_host_id', 'Info_nPos', 'Info_nNeg', 'Info_type', 'Info_window']\n",
    "\n",
    "# Drop the specified columns\n",
    "df = df.drop(columns_to_drop,axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "tzVJkQBAIvyW",
    "outputId": "5a4b83af-ae5c-48b5-c753-0692225f11a4"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "2jAop9LJIv1A",
    "outputId": "cab0cbf1-e617-4ee9-a7f3-007f443efae1"
   },
   "outputs": [],
   "source": [
    "# Split dataset into training, validation, and test sets\n",
    "train_inds, val_inds, test_inds = [], [], []\n",
    "group_splitter = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_val_inds, test_inds in group_splitter.split(df, groups=df['Info_cluster']):\n",
    "    train_inds, val_inds = next(GroupShuffleSplit(n_splits=1, test_size=0.25, random_state=42).split(df.iloc[train_val_inds], groups=df.iloc[train_val_inds]['Info_cluster']))\n",
    "    \n",
    "train_df = df.iloc[train_inds]\n",
    "val_df = df.iloc[val_inds]\n",
    "test_df = df.iloc[test_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2574, 1282)\n",
      "(22939, 1282)\n",
      "(47150, 1282)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(val_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Ljub1Mmy_-3w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts: -1    2000\n",
      " 1     574\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check class balance\n",
    "class_counts = train_df['Class'].value_counts()\n",
    "print('Class counts:', class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2iGGcZPKIv3t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72663 entries, 0 to 72662\n",
      "Columns: 1282 entries, Info_cluster to feat_esm1b_1279\n",
      "dtypes: float64(1280), int64(2)\n",
      "memory usage: 710.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Explore the dataset\n",
    "df.head()\n",
    "df.shape\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "F0lI-KBVIv6Z",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Class', ylabel='count'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize class balance\n",
    "sns.countplot(x='Class', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "nuKmyKw3I3QB",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_esm1b_0       1912\n",
      "feat_esm1b_1       1912\n",
      "feat_esm1b_2       1912\n",
      "feat_esm1b_3       1912\n",
      "feat_esm1b_4       1912\n",
      "                   ... \n",
      "feat_esm1b_1275    1912\n",
      "feat_esm1b_1276    1912\n",
      "feat_esm1b_1277    1912\n",
      "feat_esm1b_1278    1912\n",
      "feat_esm1b_1279    1912\n",
      "Length: 1280, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Investigate missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jqT1GzDJI3S-"
   },
   "outputs": [],
   "source": [
    "# Investigate correlations between features\n",
    "# corr_matrix = df.drop(columns=['Info_cluster', 'Class']).corr()\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# sns.heatmap(corr_matrix, cmap='coolwarm', center=0, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "uWXH2StqI3WE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info_cluster          0\n",
      "Class                 0\n",
      "feat_esm1b_0       1912\n",
      "feat_esm1b_1       1912\n",
      "feat_esm1b_2       1912\n",
      "                   ... \n",
      "feat_esm1b_1275    1912\n",
      "feat_esm1b_1276    1912\n",
      "feat_esm1b_1277    1912\n",
      "feat_esm1b_1278    1912\n",
      "feat_esm1b_1279    1912\n",
      "Length: 1282, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "SI-3yIjPI3ZH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Drop rows containing missing values\n",
    "df_no_missing = df.dropna(inplace=True)\n",
    "print(df_no_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "_CupDDl9I3bp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        False\n",
      "1        False\n",
      "2        False\n",
      "3        False\n",
      "4        False\n",
      "         ...  \n",
      "72658    False\n",
      "72659    False\n",
      "72660    False\n",
      "72661    False\n",
      "72662    False\n",
      "Length: 70751, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "duplicates = df.duplicated()\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "-1pjfDYcI3c-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info_cluster       7.327364\n",
      "Class             -0.151986\n",
      "feat_esm1b_0      -0.387981\n",
      "feat_esm1b_1       0.193781\n",
      "feat_esm1b_2       0.090272\n",
      "                     ...   \n",
      "feat_esm1b_1275    0.903363\n",
      "feat_esm1b_1276    0.469093\n",
      "feat_esm1b_1277   -0.866875\n",
      "feat_esm1b_1278   -0.667644\n",
      "feat_esm1b_1279   -1.329682\n",
      "Length: 1282, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate skewness of each numerical feature\n",
    "skewness = df.skew()\n",
    "print(skewness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "KRM8uy_eIv9O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info_cluster       7.327364\n",
      "feat_esm1b_61     -1.124499\n",
      "feat_esm1b_98     -1.131143\n",
      "feat_esm1b_131     1.176991\n",
      "feat_esm1b_149     1.021266\n",
      "feat_esm1b_159    -1.005051\n",
      "feat_esm1b_304     1.134366\n",
      "feat_esm1b_313    -1.153485\n",
      "feat_esm1b_330    -1.178132\n",
      "feat_esm1b_358     1.173644\n",
      "feat_esm1b_425    -1.051719\n",
      "feat_esm1b_438     1.348175\n",
      "feat_esm1b_450     2.052672\n",
      "feat_esm1b_478     1.031640\n",
      "feat_esm1b_518    -1.259561\n",
      "feat_esm1b_627     1.162392\n",
      "feat_esm1b_697    -1.001831\n",
      "feat_esm1b_715     1.029762\n",
      "feat_esm1b_767     1.047922\n",
      "feat_esm1b_769    -1.611065\n",
      "feat_esm1b_802    -1.030325\n",
      "feat_esm1b_864     1.115707\n",
      "feat_esm1b_885     1.180971\n",
      "feat_esm1b_908    -1.505715\n",
      "feat_esm1b_946    -1.362466\n",
      "feat_esm1b_947     1.053892\n",
      "feat_esm1b_1006   -1.106576\n",
      "feat_esm1b_1013   -1.613632\n",
      "feat_esm1b_1014    1.151940\n",
      "feat_esm1b_1023    1.118887\n",
      "feat_esm1b_1075   -1.045540\n",
      "feat_esm1b_1097    1.059778\n",
      "feat_esm1b_1127   -1.006476\n",
      "feat_esm1b_1161    1.109660\n",
      "feat_esm1b_1213   -1.318487\n",
      "feat_esm1b_1249   -1.093063\n",
      "feat_esm1b_1270    1.268643\n",
      "feat_esm1b_1274    1.159500\n",
      "feat_esm1b_1279   -1.329682\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Select features with high skewness values (|skewness| > 1)\n",
    "high_skewness = skewness[abs(skewness) > 1]\n",
    "print(high_skewness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Khm9MYMqI_e8"
   },
   "outputs": [],
   "source": [
    "# Apply t-SNE to the data\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_results = tsne.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pB8qUcX1JAIr",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the t-SNE results\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.scatter(tsne_results[:, 0], tsne_results[:, 1])\n",
    "plt.xlabel(\"t-SNE Component 1\")\n",
    "plt.ylabel(\"t-SNE Component 2\")\n",
    "plt.title(\"t-SNE Visualization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h8Oym3IyJALN"
   },
   "outputs": [],
   "source": [
    "# Apply t-SNE to the data\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_results = tsne.fit_transform(train_df)\n",
    "# Plot the t-SNE results\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.scatter(tsne_results[:, 0], tsne_results[:, 1])\n",
    "plt.xlabel(\"t-SNE Component 1\")\n",
    "plt.ylabel(\"t-SNE Component 2\")\n",
    "plt.title(\"t-SNE Visualization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KboVch6WJAN0"
   },
   "outputs": [],
   "source": [
    "# Apply t-SNE to the data\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_results = tsne.fit_transform(val_df)\n",
    "# Plot the t-SNE results\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.scatter(tsne_results[:, 0], tsne_results[:, 1])\n",
    "plt.xlabel(\"t-SNE Component 1\")\n",
    "plt.ylabel(\"t-SNE Component 2\")\n",
    "plt.title(\"t-SNE Visualization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Hg_IO4rpJAP-",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Info_cluster         Class  feat_esm1b_0  feat_esm1b_1  feat_esm1b_2  \\\n",
      "count  70751.000000  70751.000000  70751.000000  70751.000000  70751.000000   \n",
      "mean      20.216633      0.075773      0.024815      0.173018      0.113880   \n",
      "std       35.135080      0.997132      0.174920      0.176281      0.181818   \n",
      "min        8.000000     -1.000000     -0.971916     -0.904106     -0.910500   \n",
      "25%        8.000000     -1.000000     -0.081343      0.067374     -0.005635   \n",
      "50%        8.000000      1.000000      0.034574      0.172033      0.110035   \n",
      "75%       28.000000      1.000000      0.141719      0.273446      0.229405   \n",
      "max      587.000000      1.000000      0.933674      1.169529      1.206786   \n",
      "\n",
      "       feat_esm1b_3  feat_esm1b_4  feat_esm1b_5  feat_esm1b_6  feat_esm1b_7  \\\n",
      "count  70751.000000  70751.000000  70751.000000  70751.000000  70751.000000   \n",
      "mean       0.027288     -0.082433     -0.123585     -0.105387     -0.034119   \n",
      "std        0.158430      0.160356      0.186805      0.177181      0.222676   \n",
      "min       -1.007923     -0.886783     -1.206752     -1.256894     -1.147722   \n",
      "25%       -0.065599     -0.184767     -0.242151     -0.214552     -0.189494   \n",
      "50%        0.033116     -0.084928     -0.122892     -0.102315     -0.047335   \n",
      "75%        0.128856      0.018662     -0.006256      0.009932      0.119599   \n",
      "max        0.947781      0.811858      0.860858      0.771866      1.449602   \n",
      "\n",
      "       ...  feat_esm1b_1270  feat_esm1b_1271  feat_esm1b_1272  \\\n",
      "count  ...     70751.000000     70751.000000     70751.000000   \n",
      "mean   ...         0.196615        -0.079582        -0.139458   \n",
      "std    ...         0.199385         0.178071         0.185102   \n",
      "min    ...        -0.690764        -1.082297        -1.092095   \n",
      "25%    ...         0.069401        -0.191774        -0.241258   \n",
      "50%    ...         0.171464        -0.081251        -0.126713   \n",
      "75%    ...         0.287886         0.027053        -0.016749   \n",
      "max    ...         1.591888         0.902052         0.658360   \n",
      "\n",
      "       feat_esm1b_1273  feat_esm1b_1274  feat_esm1b_1275  feat_esm1b_1276  \\\n",
      "count     70751.000000     70751.000000     70751.000000     70751.000000   \n",
      "mean          0.044415        -0.847064        -0.063032         0.073024   \n",
      "std           0.178919         0.523521         0.204749         0.186501   \n",
      "min          -0.993062        -2.195828        -0.720878        -0.818839   \n",
      "25%          -0.059300        -1.198041        -0.196620        -0.053293   \n",
      "50%           0.055421        -0.940723        -0.083454         0.060956   \n",
      "75%           0.160118        -0.610000         0.037809         0.183790   \n",
      "max           0.938820         1.748948         1.177836         1.046847   \n",
      "\n",
      "       feat_esm1b_1277  feat_esm1b_1278  feat_esm1b_1279  \n",
      "count     70751.000000     70751.000000     70751.000000  \n",
      "mean         -0.014524         0.046024         0.172719  \n",
      "std           0.177808         0.210502         0.229217  \n",
      "min          -1.136675        -1.155765        -1.470563  \n",
      "25%          -0.102688        -0.070784         0.076882  \n",
      "50%           0.007127         0.067371         0.205800  \n",
      "75%           0.100678         0.187270         0.313568  \n",
      "max           0.682939         0.893074         0.971958  \n",
      "\n",
      "[8 rows x 1282 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate descriptive statistics\n",
    "stats = df.describe()\n",
    "print(stats)\n",
    "max_values = df.max()\n",
    "min_values = df.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3X_voDP8JAWc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a line chart to display max and min values\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(max_values.values, label='Max')\n",
    "ax.plot(min_values.values, label='Min')\n",
    "ax.set_xlabel('Feature Index')\n",
    "ax.set_ylabel('Value')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jaIZCek6JImO",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the range (max - min) for each numerical feature\n",
    "ranges = df.max() - df.min()\n",
    "print(ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "vUkTV98nJIvh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Info_cluster  Class\n",
       "8              1       28233\n",
       "              -1       17738\n",
       "28            -1       11199\n",
       "               1        8150\n",
       "34            -1        1083\n",
       "               1          62\n",
       "35            -1        1513\n",
       "               1         110\n",
       "36            -1         183\n",
       "               1          61\n",
       "44            -1          27\n",
       "50             1          87\n",
       "62             1         338\n",
       "              -1         186\n",
       "150           -1         283\n",
       "               1         281\n",
       "198            1          31\n",
       "              -1          12\n",
       "199            1          30\n",
       "204           -1         289\n",
       "               1         227\n",
       "206            1          20\n",
       "215            1          20\n",
       "219            1          38\n",
       "222            1          15\n",
       "225           -1         182\n",
       "               1          58\n",
       "229            1          54\n",
       "232            1          45\n",
       "256            1           7\n",
       "264            1           8\n",
       "298            1          69\n",
       "320            1          42\n",
       "489            1          20\n",
       "587            1          50\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by Info_cluster and get value counts of the target class within each group\n",
    "class_balance = df.groupby('Info_cluster')['Class'].value_counts()\n",
    "class_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "7tzpgEsiJI3m"
   },
   "outputs": [],
   "source": [
    "cluster_counts = df['Info_cluster'].value_counts()\n",
    "total_examples = len(df)\n",
    "\n",
    "split1_examples = round(total_examples * 0.65)  # Training Data\n",
    "split2_examples = round(total_examples * 0.25)  # Validation Data\n",
    "split3_examples = round(total_examples * 0.1)  # Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "7PsnAUA3_-31"
   },
   "outputs": [],
   "source": [
    "cluster_allocations = {}\n",
    "for i, count in cluster_counts.items():\n",
    "    if split1_examples >= count:\n",
    "        cluster_allocations[i] = 1\n",
    "        split1_examples -= count\n",
    "    elif split2_examples >= count:\n",
    "        cluster_allocations[i] = 2\n",
    "        split2_examples -= count\n",
    "    else:\n",
    "        cluster_allocations[i] = 3\n",
    "        split3_examples -= count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "PyumjxTb_-31",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info Cluster 8 allocated to split 1\n",
      "Info Cluster 28 allocated to split 3\n",
      "Info Cluster 35 allocated to split 2\n",
      "Info Cluster 34 allocated to split 2\n",
      "Info Cluster 150 allocated to split 2\n",
      "Info Cluster 62 allocated to split 2\n",
      "Info Cluster 204 allocated to split 2\n",
      "Info Cluster 36 allocated to split 2\n",
      "Info Cluster 225 allocated to split 2\n",
      "Info Cluster 50 allocated to split 2\n",
      "Info Cluster 298 allocated to split 2\n",
      "Info Cluster 229 allocated to split 2\n",
      "Info Cluster 587 allocated to split 2\n",
      "Info Cluster 232 allocated to split 2\n",
      "Info Cluster 198 allocated to split 2\n",
      "Info Cluster 320 allocated to split 2\n",
      "Info Cluster 219 allocated to split 2\n",
      "Info Cluster 199 allocated to split 2\n",
      "Info Cluster 44 allocated to split 2\n",
      "Info Cluster 215 allocated to split 2\n",
      "Info Cluster 489 allocated to split 2\n",
      "Info Cluster 206 allocated to split 2\n",
      "Info Cluster 222 allocated to split 1\n",
      "Info Cluster 264 allocated to split 2\n",
      "Info Cluster 256 allocated to split 2\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame()# Training Data\n",
    "val_df = pd.DataFrame()# Validation Data\n",
    "test_df = pd.DataFrame()# Testing Data\n",
    "\n",
    "for i, allocation in cluster_allocations.items():\n",
    "    current_rows = df[df['Info_cluster'] == i]\n",
    "    \n",
    "    if allocation == 1:\n",
    "        train_df = train_df.append(current_rows, ignore_index=True)\n",
    "    elif allocation == 2:\n",
    "        val_df = val_df.append(current_rows, ignore_index=True)\n",
    "    else:\n",
    "        test_df = test_df.append(current_rows, ignore_index=True)\n",
    "    \n",
    "    print(f\"Info Cluster {i} allocated to split {allocation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame()# Training Data\n",
    "val_df = pd.DataFrame()# Validation Data\n",
    "test_df = pd.DataFrame()# Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([df[df['Info_cluster'] == 8],df[df['Info_cluster'] == 50],df[df['Info_cluster'] == 199],df[df['Info_cluster'] == 206],df[df['Info_cluster'] == 150],df[df['Info_cluster'] == 222],df[df['Info_cluster'] == 232],df[df['Info_cluster'] == 198]], axis=0)\n",
    "val_df= pd.concat([df[df['Info_cluster'] == 28],df[df['Info_cluster'] == 36],df[df['Info_cluster'] == 62],df[df['Info_cluster'] == 219],df[df['Info_cluster'] == 298],df[df['Info_cluster'] == 204],df[df['Info_cluster'] == 215],df[df['Info_cluster'] == 229],df[df['Info_cluster'] == 256]], axis=0)\n",
    "test_df = pd.concat([df[df['Info_cluster'] == 34],df[df['Info_cluster'] == 35],df[df['Info_cluster'] == 44],df[df['Info_cluster'] == 225],df[df['Info_cluster'] == 264],df[df['Info_cluster'] == 320],df[df['Info_cluster'] == 489],df[df['Info_cluster'] == 587]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "iX7lbAnAJI_l"
   },
   "outputs": [],
   "source": [
    "y_train=train_df['Class']\n",
    "X_train=train_df.drop('Class',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "8bkVJsvtJOH5"
   },
   "outputs": [],
   "source": [
    "y_test=test_df['Class']\n",
    "X_test=test_df.drop('Class',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val=val_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "CqZdYLWSJOKt"
   },
   "outputs": [],
   "source": [
    "y_val=val_df['Class']\n",
    "X_val=val_df.drop('Class',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "tY9iqA9pJONo"
   },
   "outputs": [],
   "source": [
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "SREoh2cDJOQL"
   },
   "outputs": [],
   "source": [
    "normalized_train_df = scaler.fit_transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "1ANQ46aoJOSr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Info_cluster  Class  feat_esm1b_0  feat_esm1b_1  feat_esm1b_2  \\\n",
      "0             8      1      0.115278      0.105343      0.256809   \n",
      "1             8      1      0.048915     -0.060122      0.054565   \n",
      "2             8      1      0.029908     -0.069993      0.144604   \n",
      "3             8      1     -0.017817      0.063682      0.196507   \n",
      "4             8      1      0.183947     -0.002784      0.185983   \n",
      "\n",
      "   feat_esm1b_3  feat_esm1b_4  feat_esm1b_5  feat_esm1b_6  feat_esm1b_7  ...  \\\n",
      "0      0.205551     -0.162306     -0.250113     -0.039983     -0.221369  ...   \n",
      "1      0.130224     -0.243280      0.032289     -0.035078      0.149056  ...   \n",
      "2      0.031607     -0.157991      0.096214     -0.073147      0.150113  ...   \n",
      "3      0.219516      0.010169      0.048974     -0.102324     -0.071483  ...   \n",
      "4      0.299326     -0.256938      0.004182     -0.194807     -0.299934  ...   \n",
      "\n",
      "   feat_esm1b_1270  feat_esm1b_1271  feat_esm1b_1272  feat_esm1b_1273  \\\n",
      "0         0.235874        -0.186116        -0.007055         0.227716   \n",
      "1         0.014759        -0.119949        -0.016030         0.040704   \n",
      "2         0.066743        -0.165863        -0.061832         0.026400   \n",
      "3        -0.148641        -0.088860        -0.218482         0.103855   \n",
      "4         0.251960        -0.122903        -0.191698         0.142125   \n",
      "\n",
      "   feat_esm1b_1274  feat_esm1b_1275  feat_esm1b_1276  feat_esm1b_1277  \\\n",
      "0        -1.469320         0.024950         0.054577         0.142123   \n",
      "1        -1.614884         0.189634        -0.049600         0.005898   \n",
      "2        -1.353973         0.140752        -0.168214         0.114217   \n",
      "3        -1.252338        -0.000789         0.049453         0.197773   \n",
      "4        -0.985092         0.029431         0.176924         0.302354   \n",
      "\n",
      "   feat_esm1b_1278  feat_esm1b_1279  \n",
      "0         0.194421         0.471760  \n",
      "1         0.128652         0.254778  \n",
      "2        -0.002818         0.247916  \n",
      "3         0.034994         0.303203  \n",
      "4        -0.138180         0.136602  \n",
      "\n",
      "[5 rows x 1282 columns]\n"
     ]
    }
   ],
   "source": [
    "train_df_copy = train_df.copy()\n",
    "print(train_df_copy.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "PowWWc8XJbde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Class  feat_esm1b_0  feat_esm1b_1  feat_esm1b_2  feat_esm1b_3  \\\n",
      "0      1      0.115278      0.105343      0.256809      0.205551   \n",
      "1      1      0.048915     -0.060122      0.054565      0.130224   \n",
      "2      1      0.029908     -0.069993      0.144604      0.031607   \n",
      "3      1     -0.017817      0.063682      0.196507      0.219516   \n",
      "4      1      0.183947     -0.002784      0.185983      0.299326   \n",
      "\n",
      "   feat_esm1b_4  feat_esm1b_5  feat_esm1b_6  feat_esm1b_7  feat_esm1b_8  ...  \\\n",
      "0     -0.162306     -0.250113     -0.039983     -0.221369      0.016626  ...   \n",
      "1     -0.243280      0.032289     -0.035078      0.149056     -0.050518  ...   \n",
      "2     -0.157991      0.096214     -0.073147      0.150113     -0.123229  ...   \n",
      "3      0.010169      0.048974     -0.102324     -0.071483     -0.063823  ...   \n",
      "4     -0.256938      0.004182     -0.194807     -0.299934     -0.283545  ...   \n",
      "\n",
      "   feat_esm1b_1270  feat_esm1b_1271  feat_esm1b_1272  feat_esm1b_1273  \\\n",
      "0         0.235874        -0.186116        -0.007055         0.227716   \n",
      "1         0.014759        -0.119949        -0.016030         0.040704   \n",
      "2         0.066743        -0.165863        -0.061832         0.026400   \n",
      "3        -0.148641        -0.088860        -0.218482         0.103855   \n",
      "4         0.251960        -0.122903        -0.191698         0.142125   \n",
      "\n",
      "   feat_esm1b_1274  feat_esm1b_1275  feat_esm1b_1276  feat_esm1b_1277  \\\n",
      "0        -1.469320         0.024950         0.054577         0.142123   \n",
      "1        -1.614884         0.189634        -0.049600         0.005898   \n",
      "2        -1.353973         0.140752        -0.168214         0.114217   \n",
      "3        -1.252338        -0.000789         0.049453         0.197773   \n",
      "4        -0.985092         0.029431         0.176924         0.302354   \n",
      "\n",
      "   feat_esm1b_1278  feat_esm1b_1279  \n",
      "0         0.194421         0.471760  \n",
      "1         0.128652         0.254778  \n",
      "2        -0.002818         0.247916  \n",
      "3         0.034994         0.303203  \n",
      "4        -0.138180         0.136602  \n",
      "\n",
      "[5 rows x 1281 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is an existing DataFrame and 'column_to_delete' is the column name you want to remove\n",
    "train_df_copy = train_df_copy.drop(columns=['Info_cluster'])\n",
    "print(train_df_copy.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "lPQqphslJbhV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.53020521, 0.49373589, ..., 0.68967706, 0.62108709,\n",
       "        0.83804747],\n",
       "       [1.        , 0.49210988, 0.39370091, ..., 0.61151082, 0.58541704,\n",
       "        0.74442669],\n",
       "       [1.        , 0.48119878, 0.38773367, ..., 0.67366456, 0.51411463,\n",
       "        0.74146599],\n",
       "       ...,\n",
       "       [1.        , 0.46496914, 0.62707806, ..., 0.68028412, 0.48204446,\n",
       "        0.85008128],\n",
       "       [1.        , 0.49025636, 0.61818011, ..., 0.56792053, 0.52390606,\n",
       "        0.92540127],\n",
       "       [1.        , 0.55910112, 0.50527874, ..., 0.60613523, 0.5247293 ,\n",
       "        0.93410507]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the scaler to the feature data and transform it\n",
    "scaled_train_df = scaler.fit_transform(train_df_copy)\n",
    "scaled_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "kMWUAi-NJbj4"
   },
   "outputs": [],
   "source": [
    "dataframe_train_df_data_scaled = pd.DataFrame(scaled_train_df,columns=train_df_copy.columns)\n",
    "train_df.update(dataframe_train_df_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "N3LkZAAyJbmp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Info_cluster  Class  feat_esm1b_0  feat_esm1b_1  feat_esm1b_2  \\\n",
      "0                 8    1.0      0.530205      0.493736      0.642420   \n",
      "1                 8    1.0      0.492110      0.393701      0.531116   \n",
      "2                 8    1.0      0.481199      0.387734      0.580669   \n",
      "3                 8    1.0      0.453802      0.468549      0.609233   \n",
      "4                 8    1.0      0.569624      0.428366      0.603441   \n",
      "...             ...    ...           ...           ...           ...   \n",
      "45981           222    1.0      0.416722      0.629192      0.685242   \n",
      "45982           222    1.0      0.513677      0.615744      0.620637   \n",
      "45983           222    1.0      0.464969      0.627078      0.652500   \n",
      "45984           222    1.0      0.490256      0.618180      0.556202   \n",
      "45985           222    1.0      0.559101      0.505279      0.795913   \n",
      "\n",
      "       feat_esm1b_3  feat_esm1b_4  feat_esm1b_5  feat_esm1b_6  feat_esm1b_7  \\\n",
      "0          0.622160      0.443734      0.384668      0.599830      0.356657   \n",
      "1          0.580412      0.393699      0.541081      0.602248      0.499275   \n",
      "2          0.525758      0.446400      0.576488      0.583483      0.499682   \n",
      "3          0.629899      0.550306      0.550323      0.569101      0.414364   \n",
      "4          0.674131      0.385260      0.525514      0.523515      0.326408   \n",
      "...             ...           ...           ...           ...           ...   \n",
      "45981      0.573297      0.442427      0.547799      0.582139      0.328294   \n",
      "45982      0.529951      0.493082      0.540370      0.610028      0.386432   \n",
      "45983      0.648207      0.479155      0.589417      0.500766      0.493264   \n",
      "45984      0.620972      0.642169      0.500173      0.644151      0.355711   \n",
      "45985      0.688945      0.483945      0.478865      0.556761      0.454944   \n",
      "\n",
      "       ...  feat_esm1b_1270  feat_esm1b_1271  feat_esm1b_1272  \\\n",
      "0      ...         0.444944         0.392561         0.673355   \n",
      "1      ...         0.338771         0.429497         0.667489   \n",
      "2      ...         0.363732         0.403866         0.637551   \n",
      "3      ...         0.260311         0.446851         0.535157   \n",
      "4      ...         0.452668         0.427847         0.552665   \n",
      "...    ...              ...              ...              ...   \n",
      "45981  ...         0.368140         0.511636         0.528274   \n",
      "45982  ...         0.389990         0.476097         0.590926   \n",
      "45983  ...         0.418564         0.465097         0.502475   \n",
      "45984  ...         0.392537         0.404394         0.560881   \n",
      "45985  ...         0.436343         0.385079         0.594408   \n",
      "\n",
      "       feat_esm1b_1273  feat_esm1b_1274  feat_esm1b_1275  feat_esm1b_1276  \\\n",
      "0             0.622029         0.169358         0.383416         0.426119   \n",
      "1             0.522627         0.131787         0.471492         0.365867   \n",
      "2             0.515024         0.199129         0.445350         0.297267   \n",
      "3             0.556193         0.225361         0.369651         0.423155   \n",
      "4             0.576535         0.294338         0.385813         0.496878   \n",
      "...                ...              ...              ...              ...   \n",
      "45981         0.561646         0.338320         0.402337         0.366487   \n",
      "45982         0.535811         0.335833         0.399192         0.218519   \n",
      "45983         0.392985         0.324210         0.417016         0.400452   \n",
      "45984         0.548726         0.368595         0.472660         0.273980   \n",
      "45985         0.370931         0.381535         0.335495         0.375398   \n",
      "\n",
      "       feat_esm1b_1277  feat_esm1b_1278  feat_esm1b_1279  \n",
      "0             0.689677         0.621087         0.838047  \n",
      "1             0.611511         0.585417         0.744427  \n",
      "2             0.673665         0.514115         0.741466  \n",
      "3             0.721609         0.534622         0.765321  \n",
      "4             0.781618         0.440701         0.693438  \n",
      "...                ...              ...              ...  \n",
      "45981         0.692950         0.456729         0.839269  \n",
      "45982         0.574755         0.594872         0.830066  \n",
      "45983         0.680284         0.482044         0.850081  \n",
      "45984         0.567921         0.523906         0.925401  \n",
      "45985         0.606135         0.524729         0.934105  \n",
      "\n",
      "[45986 rows x 1282 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "d_aXRQOMJbpS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info_cluster       55.343775\n",
      "Class              -0.469538\n",
      "feat_esm1b_0       -0.357041\n",
      "feat_esm1b_1       -0.011433\n",
      "feat_esm1b_2        0.074060\n",
      "                     ...    \n",
      "feat_esm1b_1275     1.067669\n",
      "feat_esm1b_1276     0.575964\n",
      "feat_esm1b_1277    -0.835359\n",
      "feat_esm1b_1278    -0.633288\n",
      "feat_esm1b_1279    -1.287429\n",
      "Length: 1282, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate skewness of each numerical feature\n",
    "skewness = train_df.skew()\n",
    "print(skewness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "LXfHgES4Jbrz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info_cluster       55.343775\n",
      "feat_esm1b_61      -1.050133\n",
      "feat_esm1b_98      -1.097542\n",
      "feat_esm1b_131      1.081922\n",
      "feat_esm1b_149      1.055121\n",
      "feat_esm1b_159     -1.015260\n",
      "feat_esm1b_241     -1.148836\n",
      "feat_esm1b_244      1.122161\n",
      "feat_esm1b_304      1.127208\n",
      "feat_esm1b_313     -1.183204\n",
      "feat_esm1b_330     -1.098307\n",
      "feat_esm1b_358      1.101140\n",
      "feat_esm1b_425     -1.040371\n",
      "feat_esm1b_438      1.296835\n",
      "feat_esm1b_450      1.830629\n",
      "feat_esm1b_518     -1.171201\n",
      "feat_esm1b_629      1.012841\n",
      "feat_esm1b_682     -1.103162\n",
      "feat_esm1b_769     -1.593929\n",
      "feat_esm1b_777     -1.070246\n",
      "feat_esm1b_847      1.034925\n",
      "feat_esm1b_852      1.062366\n",
      "feat_esm1b_864      1.212421\n",
      "feat_esm1b_885      1.100630\n",
      "feat_esm1b_908     -1.366974\n",
      "feat_esm1b_946     -1.315168\n",
      "feat_esm1b_947      1.009481\n",
      "feat_esm1b_1006    -1.027390\n",
      "feat_esm1b_1013    -1.572593\n",
      "feat_esm1b_1014     1.057464\n",
      "feat_esm1b_1053    -1.038167\n",
      "feat_esm1b_1097     1.056711\n",
      "feat_esm1b_1104    -1.001034\n",
      "feat_esm1b_1161     1.039306\n",
      "feat_esm1b_1204    -1.030731\n",
      "feat_esm1b_1213    -1.152596\n",
      "feat_esm1b_1249    -1.026364\n",
      "feat_esm1b_1270     1.058003\n",
      "feat_esm1b_1274     1.142545\n",
      "feat_esm1b_1275     1.067669\n",
      "feat_esm1b_1279    -1.287429\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Select features with high skewness values (e.g., |skewness| > 1)\n",
    "high_skewness = skewness[abs(skewness) > 1]\n",
    "print(high_skewness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "ODGF6pRyJbuN"
   },
   "outputs": [],
   "source": [
    "# Plot the skewness\n",
    "plt.figure(figsize=(12, 10))\n",
    "skewness.plot(kind='bar')\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Skewness\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "0awS2zysOYGz"
   },
   "outputs": [],
   "source": [
    "importances = mutual_info_classif(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "QAfGPelTOZ58"
   },
   "outputs": [],
   "source": [
    "feat_importances=pd.Series(importances,X_train.columns[0:len(X_train.columns)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rbzMC2ocJbwh"
   },
   "outputs": [],
   "source": [
    "feat_importances.plot(kind='barh',color='teal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "j1fzQoYXJbze"
   },
   "outputs": [],
   "source": [
    "# create a PCA object with desired number of components\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# fit PCA on the training data\n",
    "pca.fit(train_df)\n",
    "\n",
    "# transform the data into principal components\n",
    "train_df_pca = pca.transform(train_df)\n",
    "test__df_pca = pca.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "t5nglpdVJoHY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of principal components selected: 381\n"
     ]
    }
   ],
   "source": [
    "# Instantiate PCA with n_components=0.95\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "# Fit and transform the training data\n",
    "train_df_pca = pca.fit_transform(train_df)\n",
    "\n",
    "# Transform the tuning and validation data\n",
    "test_df_pca = pca.transform(val_df)\n",
    "val_df_pca = pca.transform(test_df)\n",
    "\n",
    "# Print the number of principal components selected\n",
    "print(f\"Number of principal components selected: {pca.n_components_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "cD4jf8PoJoKH"
   },
   "outputs": [],
   "source": [
    "# Instantiate a random forest classifier\n",
    "rfc = RandomForestClassifier(n_estimators=100, n_jobs=-1, class_weight='balanced')\n",
    "\n",
    "# Instantiate Boruta feature selection\n",
    "boruta_feature_selector = BorutaPy(rfc, n_estimators='auto', verbose=2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "fCv9KIBTJoMz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info Cluster 8 allocated to split 2\n",
      "Info Cluster 150 allocated to split 1\n",
      "Info Cluster 50 allocated to split 1\n",
      "Info Cluster 232 allocated to split 1\n",
      "Info Cluster 198 allocated to split 1\n",
      "Info Cluster 199 allocated to split 1\n",
      "Info Cluster 206 allocated to split 1\n",
      "Info Cluster 222 allocated to split 1\n"
     ]
    }
   ],
   "source": [
    "cluster_counts = train_df['Info_cluster'].value_counts()\n",
    "total_examples = len(train_df)\n",
    "\n",
    "split1_examples = round(total_examples * 0.6)  # Training Data\n",
    "split2_examples = round(total_examples * 0.4)  # Testing Data\n",
    "\n",
    "cluster_allocations = {}\n",
    "for i, count in cluster_counts.items():\n",
    "    if split1_examples >= count:\n",
    "        cluster_allocations[i] = 1\n",
    "        split1_examples -= count\n",
    "    else:\n",
    "        cluster_allocations[i] = 2\n",
    "        split2_examples -= count\n",
    "\n",
    "train_df = pd.DataFrame()# Training Data\n",
    "test_df = pd.DataFrame()# Testing Data\n",
    "\n",
    "for i, allocation in cluster_allocations.items():\n",
    "    current_rows = df[df['Info_cluster'] == i]\n",
    "    \n",
    "    if allocation == 1:\n",
    "        train_df = train_df.append(current_rows, ignore_index=True)\n",
    "    else:\n",
    "        test_df = test_df.append(current_rows, ignore_index=True)\n",
    "    \n",
    "    print(f\"Info Cluster {i} allocated to split {allocation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Info_cluster</th>\n",
       "      <th>Class</th>\n",
       "      <th>feat_esm1b_0</th>\n",
       "      <th>feat_esm1b_1</th>\n",
       "      <th>feat_esm1b_2</th>\n",
       "      <th>feat_esm1b_3</th>\n",
       "      <th>feat_esm1b_4</th>\n",
       "      <th>feat_esm1b_5</th>\n",
       "      <th>feat_esm1b_6</th>\n",
       "      <th>feat_esm1b_7</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_esm1b_1270</th>\n",
       "      <th>feat_esm1b_1271</th>\n",
       "      <th>feat_esm1b_1272</th>\n",
       "      <th>feat_esm1b_1273</th>\n",
       "      <th>feat_esm1b_1274</th>\n",
       "      <th>feat_esm1b_1275</th>\n",
       "      <th>feat_esm1b_1276</th>\n",
       "      <th>feat_esm1b_1277</th>\n",
       "      <th>feat_esm1b_1278</th>\n",
       "      <th>feat_esm1b_1279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.227523</td>\n",
       "      <td>0.132470</td>\n",
       "      <td>0.158933</td>\n",
       "      <td>0.307387</td>\n",
       "      <td>-0.246765</td>\n",
       "      <td>-0.027730</td>\n",
       "      <td>0.201507</td>\n",
       "      <td>-0.143304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144026</td>\n",
       "      <td>-0.158679</td>\n",
       "      <td>-0.116429</td>\n",
       "      <td>-0.006377</td>\n",
       "      <td>-0.841997</td>\n",
       "      <td>-0.139761</td>\n",
       "      <td>-0.044355</td>\n",
       "      <td>-0.083693</td>\n",
       "      <td>0.166240</td>\n",
       "      <td>0.340400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.041850</td>\n",
       "      <td>0.206315</td>\n",
       "      <td>-0.159114</td>\n",
       "      <td>0.263294</td>\n",
       "      <td>-0.035497</td>\n",
       "      <td>-0.248510</td>\n",
       "      <td>0.185663</td>\n",
       "      <td>0.199593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210462</td>\n",
       "      <td>0.109581</td>\n",
       "      <td>0.068168</td>\n",
       "      <td>0.109193</td>\n",
       "      <td>-0.982957</td>\n",
       "      <td>-0.017489</td>\n",
       "      <td>-0.221715</td>\n",
       "      <td>0.163561</td>\n",
       "      <td>-0.195525</td>\n",
       "      <td>0.571705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.155975</td>\n",
       "      <td>0.303151</td>\n",
       "      <td>-0.057432</td>\n",
       "      <td>0.142286</td>\n",
       "      <td>0.142568</td>\n",
       "      <td>-0.223679</td>\n",
       "      <td>0.141198</td>\n",
       "      <td>-0.044333</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027750</td>\n",
       "      <td>-0.065439</td>\n",
       "      <td>0.024224</td>\n",
       "      <td>0.047982</td>\n",
       "      <td>-0.790832</td>\n",
       "      <td>-0.029045</td>\n",
       "      <td>-0.188507</td>\n",
       "      <td>0.095620</td>\n",
       "      <td>0.004118</td>\n",
       "      <td>0.479970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>0.056185</td>\n",
       "      <td>0.058463</td>\n",
       "      <td>0.244521</td>\n",
       "      <td>0.278990</td>\n",
       "      <td>-0.225740</td>\n",
       "      <td>-0.275116</td>\n",
       "      <td>0.246452</td>\n",
       "      <td>0.014478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128096</td>\n",
       "      <td>-0.136811</td>\n",
       "      <td>0.153944</td>\n",
       "      <td>-0.092948</td>\n",
       "      <td>-1.262759</td>\n",
       "      <td>-0.117635</td>\n",
       "      <td>-0.268348</td>\n",
       "      <td>0.243232</td>\n",
       "      <td>-0.181503</td>\n",
       "      <td>0.338583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.028689</td>\n",
       "      <td>0.254117</td>\n",
       "      <td>0.270150</td>\n",
       "      <td>0.011365</td>\n",
       "      <td>-0.188427</td>\n",
       "      <td>-0.272291</td>\n",
       "      <td>0.198643</td>\n",
       "      <td>-0.138021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118605</td>\n",
       "      <td>-0.164579</td>\n",
       "      <td>0.116733</td>\n",
       "      <td>0.076382</td>\n",
       "      <td>-0.798824</td>\n",
       "      <td>-0.092633</td>\n",
       "      <td>-0.241037</td>\n",
       "      <td>0.072947</td>\n",
       "      <td>0.128304</td>\n",
       "      <td>0.804927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029645</td>\n",
       "      <td>0.207810</td>\n",
       "      <td>0.159380</td>\n",
       "      <td>-0.034593</td>\n",
       "      <td>-0.236920</td>\n",
       "      <td>-0.211259</td>\n",
       "      <td>-0.061983</td>\n",
       "      <td>-0.153272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099327</td>\n",
       "      <td>0.058176</td>\n",
       "      <td>0.057389</td>\n",
       "      <td>-0.033304</td>\n",
       "      <td>-1.140336</td>\n",
       "      <td>-0.253039</td>\n",
       "      <td>-0.112142</td>\n",
       "      <td>-0.116256</td>\n",
       "      <td>-0.040661</td>\n",
       "      <td>0.665855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.123478</td>\n",
       "      <td>0.280116</td>\n",
       "      <td>-0.061716</td>\n",
       "      <td>0.188484</td>\n",
       "      <td>-0.082860</td>\n",
       "      <td>-0.314645</td>\n",
       "      <td>0.049608</td>\n",
       "      <td>0.174779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255017</td>\n",
       "      <td>0.006374</td>\n",
       "      <td>0.008892</td>\n",
       "      <td>0.169319</td>\n",
       "      <td>-1.094136</td>\n",
       "      <td>-0.045143</td>\n",
       "      <td>-0.263671</td>\n",
       "      <td>0.174941</td>\n",
       "      <td>-0.081687</td>\n",
       "      <td>0.615816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.225383</td>\n",
       "      <td>0.200990</td>\n",
       "      <td>0.234572</td>\n",
       "      <td>0.248151</td>\n",
       "      <td>-0.187474</td>\n",
       "      <td>-0.211690</td>\n",
       "      <td>0.249663</td>\n",
       "      <td>-0.046652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195083</td>\n",
       "      <td>-0.165389</td>\n",
       "      <td>-0.124347</td>\n",
       "      <td>-0.111438</td>\n",
       "      <td>-1.131672</td>\n",
       "      <td>0.072224</td>\n",
       "      <td>-0.009375</td>\n",
       "      <td>0.248948</td>\n",
       "      <td>0.031562</td>\n",
       "      <td>0.466665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>0.037882</td>\n",
       "      <td>0.369890</td>\n",
       "      <td>0.320213</td>\n",
       "      <td>-0.012237</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>-0.058281</td>\n",
       "      <td>-0.071040</td>\n",
       "      <td>0.012355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029288</td>\n",
       "      <td>-0.086442</td>\n",
       "      <td>-0.179355</td>\n",
       "      <td>-0.131625</td>\n",
       "      <td>-0.836974</td>\n",
       "      <td>0.017848</td>\n",
       "      <td>-0.110607</td>\n",
       "      <td>0.250130</td>\n",
       "      <td>-0.108336</td>\n",
       "      <td>0.601740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.012345</td>\n",
       "      <td>0.179917</td>\n",
       "      <td>0.032676</td>\n",
       "      <td>0.179754</td>\n",
       "      <td>-0.049852</td>\n",
       "      <td>-0.008164</td>\n",
       "      <td>0.024345</td>\n",
       "      <td>-0.346140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.323702</td>\n",
       "      <td>-0.111826</td>\n",
       "      <td>-0.228313</td>\n",
       "      <td>0.008738</td>\n",
       "      <td>-0.847412</td>\n",
       "      <td>0.120851</td>\n",
       "      <td>-0.344837</td>\n",
       "      <td>0.144155</td>\n",
       "      <td>0.079321</td>\n",
       "      <td>0.477577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.082413</td>\n",
       "      <td>0.329397</td>\n",
       "      <td>0.334620</td>\n",
       "      <td>0.117386</td>\n",
       "      <td>-0.164420</td>\n",
       "      <td>0.044418</td>\n",
       "      <td>-0.075874</td>\n",
       "      <td>-0.295036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075923</td>\n",
       "      <td>0.027196</td>\n",
       "      <td>-0.229013</td>\n",
       "      <td>0.114115</td>\n",
       "      <td>-0.814687</td>\n",
       "      <td>0.060327</td>\n",
       "      <td>-0.048528</td>\n",
       "      <td>0.147826</td>\n",
       "      <td>-0.108627</td>\n",
       "      <td>0.474592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>0.086485</td>\n",
       "      <td>0.307152</td>\n",
       "      <td>0.217229</td>\n",
       "      <td>0.039174</td>\n",
       "      <td>-0.082441</td>\n",
       "      <td>0.031005</td>\n",
       "      <td>-0.019294</td>\n",
       "      <td>-0.144032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121427</td>\n",
       "      <td>-0.036469</td>\n",
       "      <td>-0.133162</td>\n",
       "      <td>0.065509</td>\n",
       "      <td>-0.824320</td>\n",
       "      <td>0.054447</td>\n",
       "      <td>-0.304374</td>\n",
       "      <td>-0.058158</td>\n",
       "      <td>0.146085</td>\n",
       "      <td>0.453261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>0.325900</td>\n",
       "      <td>0.275126</td>\n",
       "      <td>0.252550</td>\n",
       "      <td>-0.104981</td>\n",
       "      <td>0.119558</td>\n",
       "      <td>-0.240960</td>\n",
       "      <td>0.133444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180936</td>\n",
       "      <td>-0.056175</td>\n",
       "      <td>-0.268482</td>\n",
       "      <td>-0.203199</td>\n",
       "      <td>-0.869354</td>\n",
       "      <td>0.087775</td>\n",
       "      <td>0.010198</td>\n",
       "      <td>0.125753</td>\n",
       "      <td>-0.061950</td>\n",
       "      <td>0.499651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045686</td>\n",
       "      <td>0.311182</td>\n",
       "      <td>0.100147</td>\n",
       "      <td>0.203407</td>\n",
       "      <td>0.158840</td>\n",
       "      <td>-0.041571</td>\n",
       "      <td>0.049934</td>\n",
       "      <td>-0.223826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126733</td>\n",
       "      <td>-0.164918</td>\n",
       "      <td>-0.179127</td>\n",
       "      <td>0.089806</td>\n",
       "      <td>-0.697387</td>\n",
       "      <td>0.191818</td>\n",
       "      <td>-0.208477</td>\n",
       "      <td>-0.070069</td>\n",
       "      <td>0.015236</td>\n",
       "      <td>0.674218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>0.165616</td>\n",
       "      <td>0.124435</td>\n",
       "      <td>0.535715</td>\n",
       "      <td>0.326056</td>\n",
       "      <td>-0.097228</td>\n",
       "      <td>-0.080042</td>\n",
       "      <td>-0.127359</td>\n",
       "      <td>0.033915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217962</td>\n",
       "      <td>-0.199518</td>\n",
       "      <td>-0.127836</td>\n",
       "      <td>-0.244691</td>\n",
       "      <td>-0.647252</td>\n",
       "      <td>-0.064653</td>\n",
       "      <td>-0.033121</td>\n",
       "      <td>-0.003470</td>\n",
       "      <td>0.016753</td>\n",
       "      <td>0.694391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 1282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Info_cluster  Class  feat_esm1b_0  feat_esm1b_1  feat_esm1b_2  \\\n",
       "0            222      1     -0.227523      0.132470      0.158933   \n",
       "1            222      1     -0.041850      0.206315     -0.159114   \n",
       "2            222      1     -0.155975      0.303151     -0.057432   \n",
       "3            222      1      0.056185      0.058463      0.244521   \n",
       "4            222      1     -0.028689      0.254117      0.270150   \n",
       "5            222      1      0.029645      0.207810      0.159380   \n",
       "6            222      1     -0.123478      0.280116     -0.061716   \n",
       "7            222      1     -0.225383      0.200990      0.234572   \n",
       "8            222      1      0.037882      0.369890      0.320213   \n",
       "9            222      1     -0.012345      0.179917      0.032676   \n",
       "10           222      1     -0.082413      0.329397      0.334620   \n",
       "11           222      1      0.086485      0.307152      0.217229   \n",
       "12           222      1      0.001635      0.325900      0.275126   \n",
       "13           222      1      0.045686      0.311182      0.100147   \n",
       "14           222      1      0.165616      0.124435      0.535715   \n",
       "\n",
       "    feat_esm1b_3  feat_esm1b_4  feat_esm1b_5  feat_esm1b_6  feat_esm1b_7  ...  \\\n",
       "0       0.307387     -0.246765     -0.027730      0.201507     -0.143304  ...   \n",
       "1       0.263294     -0.035497     -0.248510      0.185663      0.199593  ...   \n",
       "2       0.142286      0.142568     -0.223679      0.141198     -0.044333  ...   \n",
       "3       0.278990     -0.225740     -0.275116      0.246452      0.014478  ...   \n",
       "4       0.011365     -0.188427     -0.272291      0.198643     -0.138021  ...   \n",
       "5      -0.034593     -0.236920     -0.211259     -0.061983     -0.153272  ...   \n",
       "6       0.188484     -0.082860     -0.314645      0.049608      0.174779  ...   \n",
       "7       0.248151     -0.187474     -0.211690      0.249663     -0.046652  ...   \n",
       "8      -0.012237      0.003041     -0.058281     -0.071040      0.012355  ...   \n",
       "9       0.179754     -0.049852     -0.008164      0.024345     -0.346140  ...   \n",
       "10      0.117386     -0.164420      0.044418     -0.075874     -0.295036  ...   \n",
       "11      0.039174     -0.082441      0.031005     -0.019294     -0.144032  ...   \n",
       "12      0.252550     -0.104981      0.119558     -0.240960      0.133444  ...   \n",
       "13      0.203407      0.158840     -0.041571      0.049934     -0.223826  ...   \n",
       "14      0.326056     -0.097228     -0.080042     -0.127359      0.033915  ...   \n",
       "\n",
       "    feat_esm1b_1270  feat_esm1b_1271  feat_esm1b_1272  feat_esm1b_1273  \\\n",
       "0          0.144026        -0.158679        -0.116429        -0.006377   \n",
       "1          0.210462         0.109581         0.068168         0.109193   \n",
       "2         -0.027750        -0.065439         0.024224         0.047982   \n",
       "3          0.128096        -0.136811         0.153944        -0.092948   \n",
       "4          0.118605        -0.164579         0.116733         0.076382   \n",
       "5          0.099327         0.058176         0.057389        -0.033304   \n",
       "6          0.255017         0.006374         0.008892         0.169319   \n",
       "7          0.195083        -0.165389        -0.124347        -0.111438   \n",
       "8          0.029288        -0.086442        -0.179355        -0.131625   \n",
       "9          0.323702        -0.111826        -0.228313         0.008738   \n",
       "10         0.075923         0.027196        -0.229013         0.114115   \n",
       "11         0.121427        -0.036469        -0.133162         0.065509   \n",
       "12         0.180936        -0.056175        -0.268482        -0.203199   \n",
       "13         0.126733        -0.164918        -0.179127         0.089806   \n",
       "14         0.217962        -0.199518        -0.127836        -0.244691   \n",
       "\n",
       "    feat_esm1b_1274  feat_esm1b_1275  feat_esm1b_1276  feat_esm1b_1277  \\\n",
       "0         -0.841997        -0.139761        -0.044355        -0.083693   \n",
       "1         -0.982957        -0.017489        -0.221715         0.163561   \n",
       "2         -0.790832        -0.029045        -0.188507         0.095620   \n",
       "3         -1.262759        -0.117635        -0.268348         0.243232   \n",
       "4         -0.798824        -0.092633        -0.241037         0.072947   \n",
       "5         -1.140336        -0.253039        -0.112142        -0.116256   \n",
       "6         -1.094136        -0.045143        -0.263671         0.174941   \n",
       "7         -1.131672         0.072224        -0.009375         0.248948   \n",
       "8         -0.836974         0.017848        -0.110607         0.250130   \n",
       "9         -0.847412         0.120851        -0.344837         0.144155   \n",
       "10        -0.814687         0.060327        -0.048528         0.147826   \n",
       "11        -0.824320         0.054447        -0.304374        -0.058158   \n",
       "12        -0.869354         0.087775         0.010198         0.125753   \n",
       "13        -0.697387         0.191818        -0.208477        -0.070069   \n",
       "14        -0.647252        -0.064653        -0.033121        -0.003470   \n",
       "\n",
       "    feat_esm1b_1278  feat_esm1b_1279  \n",
       "0          0.166240         0.340400  \n",
       "1         -0.195525         0.571705  \n",
       "2          0.004118         0.479970  \n",
       "3         -0.181503         0.338583  \n",
       "4          0.128304         0.804927  \n",
       "5         -0.040661         0.665855  \n",
       "6         -0.081687         0.615816  \n",
       "7          0.031562         0.466665  \n",
       "8         -0.108336         0.601740  \n",
       "9          0.079321         0.477577  \n",
       "10        -0.108627         0.474592  \n",
       "11         0.146085         0.453261  \n",
       "12        -0.061950         0.499651  \n",
       "13         0.015236         0.674218  \n",
       "14         0.016753         0.694391  \n",
       "\n",
       "[15 rows x 1282 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "kGMOlDW0JoQU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts after resampling: -1    295\n",
      " 1    295\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate the feature and target columns\n",
    "y_train = train_df['Class']\n",
    "X_train = newdf.drop(['Class'], axis=1)\n",
    "\n",
    "# Create a RandomUnderSampler object\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# Resample the training data to balance the classes\n",
    "X_train_res, y_train_res = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the class balance after resampling\n",
    "print('Class counts after resampling:', y_train_res.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DWHR1QcqLhAU"
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "aq-Ksfn4JoUp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.37      0.00      0.01      2805\n",
      "           1       0.11      0.95      0.19       350\n",
      "\n",
      "    accuracy                           0.11      3155\n",
      "   macro avg       0.24      0.48      0.10      3155\n",
      "weighted avg       0.34      0.11      0.03      3155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a classifier on the balanced dataset\n",
    "classifier = LogisticRegression(random_state=42)\n",
    "classifier.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict and evaluate the classifier's performance\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "epRjkteaJoWR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.64      0.08      0.14     11857\n",
      "           1       0.44      0.94      0.60      8964\n",
      "\n",
      "    accuracy                           0.45     20821\n",
      "   macro avg       0.54      0.51      0.37     20821\n",
      "weighted avg       0.55      0.45      0.34     20821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a classifier on the balanced dataset\n",
    "classifier = LogisticRegression(random_state=42)\n",
    "classifier.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict and evaluate the classifier's performance\n",
    "y_pred = classifier.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "ho0kwjFCJoZv"
   },
   "outputs": [],
   "source": [
    "# Define the SMOTE object\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Define the logistic regression object\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "param_grid = {'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "              'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "              'max_iter': [100, 500, 1000],\n",
    "              'class_weight': ['balanced', None]}\n",
    "\n",
    "# Define the scoring metric\n",
    "scoring = make_scorer(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "xHwX0pkNNwtW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.859080691305136\n",
      "Best Score: 0.5843625359035267\n",
      "Best Hyperparameters: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "group=np.array(X_val['Info_cluster'])\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Define search space\n",
    "space = dict()\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "space['C'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "\n",
    "# Define group k-fold cross-validator\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "# Define search \n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=gkf)\n",
    "\n",
    "# Fit the model\n",
    "result = search.fit(X_val, y_val, groups=group)\n",
    "\n",
    "# Calculate probabilities for the positive class\n",
    "y_proba = search.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Compute ROC AUC score\n",
    "roc_auc = roc_auc_score(y_val, y_proba)\n",
    "print('ROC AUC Score:', roc_auc)\n",
    "\n",
    "# Print best score and hyperparameters\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)\n",
    "\n",
    "BestScore_LogisticRegression = result.best_score_\n",
    "BestHyperParameters_LogisticRegression = result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "ssQr9A1wQrqa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.5871334051921799\n",
      "Best Score: 0.5729648872299978\n",
      "Best Hyperparameters: {'criterion': 'gini', 'max_depth': 2, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Define search space\n",
    "space = dict()\n",
    "space['criterion'] = ['gini', 'entropy']\n",
    "space['splitter'] = ['best', 'random']\n",
    "space['max_depth'] = [None, 1, 2, 4, 6, 8, 10]\n",
    "space['min_samples_split'] = [2, 5, 10]\n",
    "space['min_samples_leaf'] = [1, 2, 4]\n",
    "\n",
    "# Define group k-fold cross-validator\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "# Define search\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=gkf)\n",
    "\n",
    "# Fit the model\n",
    "result = search.fit(X_val, y_val, groups=group)\n",
    "\n",
    "# Calculate probabilities for the positive class\n",
    "y_proba = search.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Compute ROC AUC score\n",
    "roc_auc = roc_auc_score(y_val, y_proba)\n",
    "print('ROC AUC Score:', roc_auc)\n",
    "\n",
    "# Print best score and hyperparameters\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)\n",
    "\n",
    "BestScore_DecisionTree = result.best_score_\n",
    "BestHyperParameters_DecisionTree = result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJ0vaFJPSyoi"
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "# Define search space\n",
    "space = dict()\n",
    "space['n_estimators'] = [10, 50, 100, 200]\n",
    "space['criterion'] = ['gini', 'entropy']\n",
    "space['max_depth'] = [None, 1, 2, 4, 6, 8, 10]\n",
    "space['min_samples_split'] = [2, 5, 10]\n",
    "space['min_samples_leaf'] = [1, 2, 4]\n",
    "\n",
    "# Define group k-fold cross-validator\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "# Define search\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=gkf)\n",
    "\n",
    "# Fit the model\n",
    "result = search.fit(X_val, y_val, groups=group)\n",
    "\n",
    "# Calculate probabilities for the positive class\n",
    "y_proba = search.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Compute ROC AUC score\n",
    "roc_auc = roc_auc_score(y_val, y_proba)\n",
    "print('ROC AUC Score:', roc_auc)\n",
    "\n",
    "# Print best score and hyperparameters\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)\n",
    "\n",
    "BestScore_RandomForest = result.best_score_\n",
    "BestHyperParameters_RandomForest = result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DAvZQZFA8NNh"
   },
   "outputs": [],
   "source": [
    "pipe=Pipeline([\n",
    "('scaler', StandardScaler()), ('selector',SelectKBest(score_func=mutual_info_classif)),\n",
    "('classifier', RandomForestClassifier(n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features='sqrt', max_depth=20, bootstrap=True, class_weight='balanced', random_state=42))\n",
    "])\n",
    "#Fit the pipeline to the training data\n",
    "result=pipe.fit(X_train,y_train)\n",
    "y_pred=pipe.predict(X_test)\n",
    "\n",
    "accuracy=accuracy_score(y_test,y_pred)\n",
    "print('AUC-ROC score :',roc_auc_score(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": "-1",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "153.438px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
